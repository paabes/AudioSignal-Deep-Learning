# Analysing Audio Data With Deep Neural Nets
## Project Overview:

The aim of this project was to achieve 3 goals:

1. Test my understanding of mathematics and intuition behind Deep Neural Networks by trying to reconstruct a simple multilayer perception model with backpropagation, gradient descent and fully working train / test methods:

![alt text](https://github.com/paabes/AudioSignal-Deep-Learning/blob/main/3%20-%20backpropagation%20from%20scratch%20/figures/loss%20functional.png)

2. Explore some of the techniques behind audio signal processing, including **Fast Fourier Transform**, **STFT**, **MFCC**'s and more:
 
![alt text](https://github.com/paabes/AudioSignal-Deep-Learning/blob/main/Audio%20Signal%20Preprocessing/figures/MFC.png)

3. Implement Conventional, Convenutional and Recurrent Neural Network models to classify music dataset into 10 different genres based on their Mel-Frequency Coefficients, then evaluate, tune and compare their performance:

![alt text](https://github.com/paabes/AudioSignal-Deep-Learning/blob/main/Classifying%20Music%20Genre%20With%20ANNs/figures/CNN_accuracy_eval.jpg)

**More detailed commentary is attached to each corresponding directory.**